# Hi ğŸ‘‹, I'm Harshal Katkar  

ğŸš€ **Data Engineer | Backend Engineer (Python)**  
ğŸ“ Pune, India  

Data Engineer with over **one year of professional experience** designing, building, and maintaining **scalable data pipelines and backend data services**. Strong experience in **ETL workflows**, **batch and streaming data processing**, and transforming raw data into **analytics-ready datasets** using Python and SQL. Proven ability to build **reliable, maintainable data platforms** that support reporting, analytics, and downstream business use cases.


## ğŸ› ï¸ Tech Stack

**Programming & Querying:** Python, SQL, PySpark, Shell Scripting, FastAPI  

**Data Engineering:** ETL/ELT Pipelines, Batch & Streaming Processing, Data Ingestion & Transformation, Data Modeling (Star Schema, Medallion Architecture), Workflow Orchestration, Data Quality  

**Databases & Storage:** PostgreSQL, MySQL, MongoDB, SQLite, SQL Server  

**Big Data & Distributed Systems:** Apache Spark, Spark Structured Streaming, Apache Kafka  

**Tools & Platforms:** Apache Airflow, Docker, Git, GitHub Actions, Databricks, Streamlit, VS Code, Jupyter Notebook, CI/CD Pipelines  


## ğŸ’¼ Experience

### **Data Engineer** â€” Navadr Technologies Solutions  
ğŸ“… *Jan 2025 â€“ Present* | Pune  

- Designed and developed **Python-based ETL pipelines** ingesting data from **REST APIs and CSV sources**, processing approximately **1M records per week**
- Implemented and scheduled **Apache Airflow DAGs** on daily and hourly intervals, improving **data availability and pipeline reliability**
- Performed **data cleansing, normalization, and transformation** to deliver **analytics-ready datasets** for reporting and downstream consumption
- Built and maintained data workflows in **Dockerized environments**, following **Git-based collaborative development practices**


---

### **Data Engineer Intern** â€” TechneAi Pvt. Ltd.  
ğŸ“… *Aug 2024 â€“ Dec 2024* | Pune  

- Developed **Python-based data ingestion scripts** to process structured CSV datasets and load them into **MongoDB**
- Built and maintained **REST APIâ€“driven backend services** to support data ingestion and system integration workflows
- Implemented basic **data validation and transformation logic** to ensure data consistency and reliability
- Contributed to the development of **end-to-end data pipelines**, gaining exposure to ingestion, processing, and storage layers


## ğŸ“Œ Featured Projects

### ğŸ”¹ SQL Server Data Warehouse
**Tech:** SQL Server, SSIS, T-SQL  
- Built a modern **Data Warehouse using Medallion Architecture**
- Designed **star schema**, stored procedures, and ETL pipelines
- Optimized performance using **indexing, views, and partitioning**

---

### ğŸ”¹ COVID-19 ETL Pipeline
**Tech:** Python, Pandas, Apache Airflow, PostgreSQL, Streamlit, Docker  
- Built a batch ETL pipeline extracting data from public REST APIs
- Transformed and loaded data into PostgreSQL
- Visualized insights using **Streamlit dashboards**

---

## ğŸ† Achievements
- ğŸ¥‡ **Employee of the Month â€“ March 2025** (Navadr Technologies)
- ğŸ” Implemented **Role-Based Access Control (RBAC)** for a multi-tenant product
- ğŸ’» Active in **competitive coding** on HackerRank

---

## ğŸ“« Connect With Me
- ğŸ“§ Email: **harshalkatkar523@gmail.com**
- ğŸ’¼ LinkedIn: [linkedin.com/in/harshalkatkar](https://www.linkedin.com/in/harshalkatkar/)
- ğŸ§‘â€ğŸ’» GitHub: [github.com/Harshkatkar](https://github.com/Harshkatkar)

---

â­ *Always learning, building, and improving data systems.*
